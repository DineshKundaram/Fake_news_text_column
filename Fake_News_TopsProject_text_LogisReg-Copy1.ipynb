{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50047355",
   "metadata": {},
   "source": [
    "# Problem statemaent : Detecting Fake News with Python and Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f671f0",
   "metadata": {},
   "source": [
    "## What is Fake News?\n",
    "### A type of yellow journalism, fake news encapsulates pieces of news that may be hoaxes and is generally spread through social media and other online media. This is often done to further or impose certain ideas and is often achieved with political agendas. Such news items may contain false and/or exaggerated claims, and may end up being viralized by algorithms, and users may end up in a filter bubble."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d68cc8",
   "metadata": {},
   "source": [
    "#### Importing Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d0653a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "#pandas uses dataframe to alter, merge etc perform certain tasks on rows and columns\n",
    "\n",
    "import numpy as np \n",
    "#uses array format to calculate certain type of calculations quickly\n",
    "\n",
    "import re \n",
    "#re stands for Regular Expressions\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "#nltk stands for natuaral language toolkit\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer \n",
    "#apply PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "#coverts text to vectors\n",
    " \n",
    "from sklearn.model_selection import train_test_split \n",
    "#splits data ratiowise\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "#Classisfication problem \n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "#checks scores\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#encode string data to values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e99a819",
   "metadata": {},
   "source": [
    "#### - re stands for Regular Expressions means it is a sequence of characters that defines a specific search pattern and using which you can match or substitute patterns inside a text with least amount of code. Eg: \" i was born in *year @&1995\", so re.sub('*&@',\"\",sentence) this removes all special characters with nothing.\n",
    "\n",
    "#### - nltk - from this package we are importing stopwords, these are words which have less meaning in sentences. Corpus means body of that document which docs in rows\n",
    "\n",
    "#### - PorterStemmer is stemming algorithm which uses to do remove prefixes and suffixes of words into root words. eg. actor, actress, -- root word act.\n",
    "\n",
    "#### - TfidfVectorizer is term frequency and inverse document frequency uses to convert text to vectors, give priority to most frequent words and rare words as well, uses log function in idf vectors which is monotonous function but it does not take symantic words like taste and delicious have same meaning but tfidf uses different dimensions of words\n",
    "\n",
    "#### - Stopwords are those which does not add much values to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66fc9b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dines\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# downloading stopwords from nltk library\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7562864d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# checking which are stopwords to get general idea\n",
    "\n",
    "print(stopwords.words('english'))  \n",
    "#here english language stopword printed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3716ffc6",
   "metadata": {},
   "source": [
    "#### stopwords have also listed 'not' word sometimes if 'not' includes in any sentences make sentence meaning same so we can exclude 'not' word from stopword list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59021df2",
   "metadata": {},
   "source": [
    "### Data/Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fadb4fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6903</td>\n",
       "      <td>Tehran, USA</td>\n",
       "      <td>\\nI’m not an immigrant, but my grandparents ...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7341</td>\n",
       "      <td>Girl Horrified At What She Watches Boyfriend D...</td>\n",
       "      <td>Share This Baylee Luciani (left), Screenshot o...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>95</td>\n",
       "      <td>‘Britain’s Schindler’ Dies at 106</td>\n",
       "      <td>A Czech stockbroker who saved more than 650 Je...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "5        6903                                        Tehran, USA   \n",
       "6        7341  Girl Horrified At What She Watches Boyfriend D...   \n",
       "7          95                  ‘Britain’s Schindler’ Dies at 106   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  \n",
       "5    \\nI’m not an immigrant, but my grandparents ...  FAKE  \n",
       "6  Share This Baylee Luciani (left), Screenshot o...  FAKE  \n",
       "7  A Czech stockbroker who saved more than 650 Je...  REAL  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading csv data\n",
    "news = pd.read_csv('news.csv')\n",
    "news.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed4e6c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6335, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#chekcing shape of dataset\n",
    "news.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31332b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "title         0\n",
       "text          0\n",
       "label         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking null values\n",
    "news.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2396f097",
   "metadata": {},
   "source": [
    "#### -no null values present in any column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e22fa05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating input and output variable\n",
    "train = news['text']\n",
    "test = news['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae0be90b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6335,), (6335,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# always check input and output shape and data\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1a8fe9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now target column has string values so need to encode into interger\n",
    "le = LabelEncoder()\n",
    "test = le.fit_transform(test)\n",
    "test # here, 0 represents Fake_news, 1 represents Real_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5c9b7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating PorterStemmer variable\n",
    "port_stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6667ba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying stemming Process\n",
    "def stemming(content): #defining function\n",
    "    \n",
    "    stemmed_content = re.sub('[^a-zA-Z]',' ',content) \n",
    "    #here applying regular expression substitute, '^' means excluding a to z characters, replacing with '_'(space) in content \n",
    "    \n",
    "    stemmed_content = stemmed_content.lower()\n",
    "    #apply string values in lower case\n",
    "    \n",
    "    stemmed_content = stemmed_content.split() \n",
    "    #splitting strings\n",
    "    \n",
    "    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
    "    #applying PorterStemmer algorithm on stemmed_content which are not in stopwords library\n",
    "    \n",
    "    stemmed_content =' '.join(stemmed_content)\n",
    "    #joining all words again into same sentences\n",
    "    \n",
    "    return stemmed_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c216060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying stemming on train dataset\n",
    "train = train.apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "150f392d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     daniel greenfield shillman journal fellow free...\n",
       "1     googl pinterest digg linkedin reddit stumbleup...\n",
       "2     u secretari state john f kerri said monday sto...\n",
       "3     kayde king kaydeek novemb lesson tonight dem l...\n",
       "4     primari day new york front runner hillari clin...\n",
       "5     immigr grandpar year ago arriv new york citi i...\n",
       "6     share bayle luciani left screenshot bayle caug...\n",
       "7     czech stockbrok save jewish children nazi germ...\n",
       "8     hillari clinton donald trump made inaccur clai...\n",
       "9     iranian negoti reportedli made last ditch push...\n",
       "10    cedar rapid iowa one wonder ralli entir career...\n",
       "11    donald trump organiz problem gone bad wors fla...\n",
       "12    click learn alexandra person essenc psychic pr...\n",
       "13    octob pretti factual except women select servi...\n",
       "14    kill obama administr rule dismantl obamacar pu...\n",
       "15    women move high offic often bring style approa...\n",
       "16    shock michel obama hillari caught glamor date ...\n",
       "17    hillari clinton bare lost presidenti elect alr...\n",
       "18    washington cnn month white hous congress wrang...\n",
       "19    page pew best data visual awesom came across b...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking after applying stemming process\n",
    "train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f50fcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data have string object so need to convert data into numerical values so computer can understand\n",
    "vectorizer = TfidfVectorizer()\n",
    "train = vectorizer.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a703479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 11498)\t0.018669004977501614\n",
      "  (0, 4952)\t0.016492946252976797\n",
      "  (0, 106)\t0.02761351227547292\n",
      "  (0, 17587)\t0.02761351227547292\n",
      "  (0, 5293)\t0.028910867392933547\n",
      "  (0, 6325)\t0.01281969349793845\n",
      "  (0, 34872)\t0.022143906642919344\n",
      "  (0, 26227)\t0.01375386384385865\n",
      "  (0, 8751)\t0.0226780256967325\n",
      "  (0, 26965)\t0.024519594414306525\n",
      "  (0, 42772)\t0.023731581997339293\n",
      "  (0, 36349)\t0.01529282822765254\n",
      "  (0, 21457)\t0.011020597155694964\n",
      "  (0, 23657)\t0.011689867576623285\n",
      "  (0, 33684)\t0.022127993048050038\n",
      "  (0, 39761)\t0.02827181627824194\n",
      "  (0, 31214)\t0.022305525686593712\n",
      "  (0, 7097)\t0.01411426717822184\n",
      "  (0, 2591)\t0.015117514678878584\n",
      "  (0, 36474)\t0.01864302037416216\n",
      "  (0, 5797)\t0.02274843807685857\n",
      "  (0, 40952)\t0.01971379102038718\n",
      "  (0, 34237)\t0.018712576655497182\n",
      "  (0, 1089)\t0.018102417756284926\n",
      "  (0, 18761)\t0.02906905996945774\n",
      "  :\t:\n",
      "  (6334, 14047)\t0.023167179277208322\n",
      "  (6334, 38604)\t0.012077162102509642\n",
      "  (6334, 36852)\t0.027692187669159592\n",
      "  (6334, 9454)\t0.06398857267178765\n",
      "  (6334, 7806)\t0.01772435132972147\n",
      "  (6334, 21693)\t0.01993658018648796\n",
      "  (6334, 39373)\t0.410183996685771\n",
      "  (6334, 17071)\t0.05087781146876611\n",
      "  (6334, 23925)\t0.037093309534701906\n",
      "  (6334, 8669)\t0.02146365523297267\n",
      "  (6334, 2375)\t0.15066171651677582\n",
      "  (6334, 42770)\t0.024052729499248977\n",
      "  (6334, 28790)\t0.012585941291343815\n",
      "  (6334, 15050)\t0.013751357959892645\n",
      "  (6334, 28418)\t0.034191993996577574\n",
      "  (6334, 29621)\t0.030379501827693493\n",
      "  (6334, 36624)\t0.01710405248878914\n",
      "  (6334, 27274)\t0.023210938716116656\n",
      "  (6334, 2032)\t0.01866867973167515\n",
      "  (6334, 42704)\t0.0217570664665555\n",
      "  (6334, 41801)\t0.01952546251514695\n",
      "  (6334, 7064)\t0.015430200181899195\n",
      "  (6334, 16964)\t0.016025189836089252\n",
      "  (6334, 11382)\t0.01541718849225356\n",
      "  (6334, 26236)\t0.06428976268719672\n"
     ]
    }
   ],
   "source": [
    "#chekcing sparse matrix after TfidfVectorizer method\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ed94f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into train and test\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(train, test, test_size=0.2, stratify=test, random_state=2)\n",
    "# stratify defines equal proportionate of real and fake news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5dc12d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5068, 43733), (1267, 43733), (5068,), (1267,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking shape of splittiing\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3e25b8",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3d83d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53400eca",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26cd4d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy score 0.9522494080505131\n"
     ]
    }
   ],
   "source": [
    "#chekcing accuracy score on training data\n",
    "\n",
    "x_train_pred = model.predict(x_train)\n",
    "training_pred = accuracy_score(x_train_pred, y_train)\n",
    "print('training accuracy score', training_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85e99144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy score 0.9171270718232044\n"
     ]
    }
   ],
   "source": [
    "#chekcing accuracy score on test data\n",
    "\n",
    "x_test_pred = model.predict(x_test)\n",
    "test_pred = accuracy_score(x_test_pred, y_test)\n",
    "print('test accuracy score', test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adea956",
   "metadata": {},
   "source": [
    "#### Making a predictive system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "431ed763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "News is Real\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# checking news label on first index\n",
    "\n",
    "x_news = x_test[0]\n",
    "prediction = model.predict(x_news)\n",
    "\n",
    "print(prediction)\n",
    "\n",
    "if (prediction[0]==0):\n",
    "    print('News is Fake')\n",
    "else:\n",
    "    print('News is Real')\n",
    "    \n",
    "print(y_test[0])\n",
    "# checking label in y_test, its predicted correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86424bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "News is Fake\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# checking news label on other index's\n",
    "\n",
    "x_news = x_test[1]\n",
    "prediction = model.predict(x_news)\n",
    "\n",
    "print(prediction)\n",
    "\n",
    "if (prediction[0]==0):\n",
    "    print('News is Fake')\n",
    "else:\n",
    "    print('News is Real')\n",
    "    \n",
    "print(y_test[1])\n",
    "# checking label in y_test, its predicted correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a673121",
   "metadata": {},
   "source": [
    "#### Conclusion : Model is performing well, we can improve accuracy score changing vectors and stemming methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eeb5d936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#to save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a305b32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fake_news_text', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "# here saving trained model as \"fake_news_text\" as file name, wb=write_binary to save model using pickle library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e2f4010",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fake_news_text.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
